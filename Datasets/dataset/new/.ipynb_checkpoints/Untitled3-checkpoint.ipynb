{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hYcIhNuKJ5_O",
    "outputId": "d67a24e4-44f1-4ce2-e157-d9297cecd7a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive/\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "import os\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VgthC9JsPXka",
    "outputId": "cc541915-2872-4943-8f31-5e1ef7e70d87"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bahan  test  train  validation\n"
     ]
    }
   ],
   "source": [
    "base_dir = 'D:/FILE/KULIAH/PPTI BCA/CAWU 4/Software Engineering/Dataset/predict/bahan'\n",
    "!ls \"D:/FILE/KULIAH/PPTI BCA/CAWU 4/Software Engineering/Dataset/predict/bahan\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CzDqLs9OPfuA"
   },
   "outputs": [],
   "source": [
    "bahan_dir = os.path.join(base_dir, 'bahan')\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "validation_dir = os.path.join(base_dir, 'validation')\n",
    "test_dir = os.path.join(base_dir, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dNTH7vDbPqC8"
   },
   "outputs": [],
   "source": [
    "mn_dir = os.path.join(bahan_dir, 'Melanocytic Nevi/')\n",
    "melanoma_dir = os.path.join(bahan_dir, 'Melanoma/')\n",
    "normal_dir = os.path.join(bahan_dir, 'Normal/')\n",
    "ringworm_dir = os.path.join(bahan_dir, 'Ringworm/')\n",
    "vitiligo_dir = os.path.join(bahan_dir, 'Vitiligo/')\n",
    "\n",
    "train_mn = os.path.join(train_dir, 'Melanocytic Nevi/')\n",
    "train_melanoma = os.path.join(train_dir, 'Melanoma/')\n",
    "train_normal = os.path.join(train_dir, 'Normal/')\n",
    "train_ringworm = os.path.join(train_dir, 'Ringworm/')\n",
    "train_vitiligo = os.path.join(train_dir, 'Vitiligo/')\n",
    "\n",
    "validation_mn = os.path.join(validation_dir, 'Melanocytic Nevi/')\n",
    "validation_melanoma = os.path.join(validation_dir, 'Melanoma/')\n",
    "validation_normal = os.path.join(validation_dir, 'Normal/')\n",
    "validation_ringworm = os.path.join(validation_dir, 'Ringworm/')\n",
    "validation_vitiligo = os.path.join(validation_dir, 'Vitiligo/')\n",
    "\n",
    "test_mn = os.path.join(test_dir, 'Melanocytic Nevi/')\n",
    "test_melanoma = os.path.join(test_dir, 'Melanoma/')\n",
    "test_normal = os.path.join(test_dir, 'Normal/')\n",
    "test_ringworm = os.path.join(test_dir, 'Ringworm/')\n",
    "test_vitiligo = os.path.join(test_dir, 'Vitiligo/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Kx51GSYzQrEQ"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from shutil import copyfile\n",
    "\n",
    "def train_val_test_split(source, train, val, test, train_ratio, val_ratio):\n",
    "  total_size = len(os.listdir(source))\n",
    "  train_size = int(train_ratio * total_size)\n",
    "  val_size = int(val_ratio * (total_size - train_size))\n",
    "  test_size = int(total_size - train_size - val_size)\n",
    "\n",
    "  randomized = random.sample(os.listdir(source), total_size)\n",
    "  train_files = randomized[0:train_size]\n",
    "  val_files = randomized[train_size:(train_size + val_size)]\n",
    "  test_files = randomized[(train_size + val_size):total_size]\n",
    "\n",
    "  for i in train_files:\n",
    "    i_file = source + i\n",
    "    destination = train + i\n",
    "    copyfile(i_file, destination)\n",
    "\n",
    "  for i in val_files:\n",
    "    i_file = source + i\n",
    "    destination = val + i\n",
    "    copyfile(i_file, destination)\n",
    "\n",
    "  for i in test_files:\n",
    "    i_file = source + i\n",
    "    destination = test + i\n",
    "    copyfile(i_file, destination)\n",
    "\n",
    "train_ratio = 0.8\n",
    "val_ratio = 0.5\n",
    "\n",
    "source_00 = mn_dir\n",
    "train_00 = train_mn\n",
    "val_00 = validation_mn\n",
    "test_00 = test_mn\n",
    "train_val_test_split(source_00, train_00, val_00, test_00, train_ratio, val_ratio)\n",
    "\n",
    "source_01 = melanoma_dir\n",
    "train_01 = train_melanoma\n",
    "val_01 = validation_melanoma\n",
    "test_01 = test_melanoma\n",
    "train_val_test_split(source_01, train_01, val_01, test_01, train_ratio, val_ratio)\n",
    "\n",
    "source_02 = normal_dir\n",
    "train_02 = train_normal\n",
    "val_02 = validation_normal\n",
    "test_02 = test_normal\n",
    "train_val_test_split(source_02, train_02, val_02, test_02, train_ratio, val_ratio)\n",
    "\n",
    "source_03 = ringworm_dir\n",
    "train_03 = train_ringworm\n",
    "val_03 = validation_ringworm\n",
    "test_03 = test_ringworm\n",
    "train_val_test_split(source_03, train_03, val_03, test_03, train_ratio, val_ratio)\n",
    "\n",
    "source_04 = vitiligo_dir\n",
    "train_04 = train_vitiligo\n",
    "val_04 = validation_vitiligo\n",
    "test_04 = test_vitiligo\n",
    "train_val_test_split(source_04, train_04, val_04, test_04, train_ratio, val_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g7fqq6-Wmyrj"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FjkcSSRsiYHR",
    "outputId": "3b22f474-5157-4507-c04d-30bb201d5fdf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1200 images belonging to 5 classes.\n",
      "Found 150 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    rescale = 1./255,\n",
    "    rotation_range = 30,\n",
    "    horizontal_flip = True,\n",
    "    shear_range = 0.3,\n",
    "    fill_mode = 'nearest',\n",
    "    width_shift_range = 0.2,\n",
    "    height_shift_range = 0.2,\n",
    "    zoom_range = 0.1\n",
    ")\n",
    "\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size = (320,320),\n",
    "    batch_size = 96,\n",
    "    class_mode = 'categorical'\n",
    ")\n",
    "\n",
    "val_generator = datagen.flow_from_directory(\n",
    "    validation_dir,\n",
    "    target_size = (320,320),\n",
    "    batch_size = 96,\n",
    "    class_mode = 'categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OleEad9JmDgu"
   },
   "outputs": [],
   "source": [
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "  def on_epoch_end(self, epoch, logs={}):\n",
    "    if(logs.get('accuracy') > 0.99):\n",
    "      print('\\nAkurasi mencapai 99%')\n",
    "      self.model_stop_training = True\n",
    "\n",
    "callbacks = myCallback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hEpsVyMYmD9w"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(150,150,3)),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(200, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.3,seed=112),\n",
    "    tf.keras.layers.Dense(500, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.5,seed=112),\n",
    "    tf.keras.layers.Dense(2, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ilW-Xgi4mJ90",
    "outputId": "1a620f77-d94c-4042-8f2b-60834ee4abbf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 148, 148, 16)      448       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 74, 74, 16)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 72, 72, 32)        4640      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 36, 36, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 34, 34, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 17, 17, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 18496)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 200)               3699400   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 200)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 500)               100500    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 500)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 2)                 1002      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,824,486\n",
      "Trainable params: 3,824,486\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MshPegJsmLT8"
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer = 'Adam',\n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "T3g8UhHbmMb-",
    "outputId": "b160f898-5880-4fb5-bc6f-c8ff43f7eaa0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-c3c32a38a563>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m history = model.fit(train_generator,\n\u001b[0m\u001b[1;32m      2\u001b[0m                     \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                     callbacks = [callbacks])\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node 'sequential/flatten/Reshape' defined at (most recent call last):\n    File \"/usr/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/usr/lib/python3.8/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/usr/local/lib/python3.8/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"/usr/local/lib/python3.8/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n      app.start()\n    File \"/usr/local/lib/python3.8/dist-packages/ipykernel/kernelapp.py\", line 612, in start\n      self.io_loop.start()\n    File \"/usr/local/lib/python3.8/dist-packages/tornado/platform/asyncio.py\", line 149, in start\n      self.asyncio_loop.run_forever()\n    File \"/usr/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n      self._run_once()\n    File \"/usr/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n      handle._run()\n    File \"/usr/lib/python3.8/asyncio/events.py\", line 81, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/usr/local/lib/python3.8/dist-packages/tornado/ioloop.py\", line 690, in <lambda>\n      lambda f: self._run_callback(functools.partial(callback, future))\n    File \"/usr/local/lib/python3.8/dist-packages/tornado/ioloop.py\", line 743, in _run_callback\n      ret = callback()\n    File \"/usr/local/lib/python3.8/dist-packages/tornado/gen.py\", line 787, in inner\n      self.run()\n    File \"/usr/local/lib/python3.8/dist-packages/tornado/gen.py\", line 748, in run\n      yielded = self.gen.send(value)\n    File \"/usr/local/lib/python3.8/dist-packages/ipykernel/kernelbase.py\", line 381, in dispatch_queue\n      yield self.process_one()\n    File \"/usr/local/lib/python3.8/dist-packages/tornado/gen.py\", line 225, in wrapper\n      runner = Runner(result, future, yielded)\n    File \"/usr/local/lib/python3.8/dist-packages/tornado/gen.py\", line 714, in __init__\n      self.run()\n    File \"/usr/local/lib/python3.8/dist-packages/tornado/gen.py\", line 748, in run\n      yielded = self.gen.send(value)\n    File \"/usr/local/lib/python3.8/dist-packages/ipykernel/kernelbase.py\", line 365, in process_one\n      yield gen.maybe_future(dispatch(*args))\n    File \"/usr/local/lib/python3.8/dist-packages/tornado/gen.py\", line 209, in wrapper\n      yielded = next(result)\n    File \"/usr/local/lib/python3.8/dist-packages/ipykernel/kernelbase.py\", line 268, in dispatch_shell\n      yield gen.maybe_future(handler(stream, idents, msg))\n    File \"/usr/local/lib/python3.8/dist-packages/tornado/gen.py\", line 209, in wrapper\n      yielded = next(result)\n    File \"/usr/local/lib/python3.8/dist-packages/ipykernel/kernelbase.py\", line 543, in execute_request\n      self.do_execute(\n    File \"/usr/local/lib/python3.8/dist-packages/tornado/gen.py\", line 209, in wrapper\n      yielded = next(result)\n    File \"/usr/local/lib/python3.8/dist-packages/ipykernel/ipkernel.py\", line 306, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"/usr/local/lib/python3.8/dist-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n      return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 2854, in run_cell\n      result = self._run_cell(\n    File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 2881, in _run_cell\n      return runner(coro)\n    File \"/usr/local/lib/python3.8/dist-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 3057, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 3249, in run_ast_nodes\n      if (await self.run_code(code, result,  async_=asy)):\n    File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 3326, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"<ipython-input-13-c3c32a38a563>\", line 1, in <module>\n      history = model.fit(train_generator,\n    File \"/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 1409, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 1051, in train_function\n      return step_function(self, iterator)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 1040, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 1030, in run_step\n      outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 889, in train_step\n      y_pred = self(x, training=True)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 490, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/base_layer.py\", line 1014, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/sequential.py\", line 374, in call\n      return super(Sequential, self).call(inputs, training=training, mask=mask)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/functional.py\", line 458, in call\n      return self._run_internal_graph(\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/functional.py\", line 596, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/base_layer.py\", line 1014, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/layers/reshaping/flatten.py\", line 98, in call\n      return tf.reshape(inputs, flattened_shape)\nNode: 'sequential/flatten/Reshape'\nInput to reshape is a tensor with 8871936 values, but the requested shape requires a multiple of 18496\n\t [[{{node sequential/flatten/Reshape}}]] [Op:__inference_train_function_1062]"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_generator,\n",
    "                    epochs = 25,\n",
    "                    validation_data=val_generator,\n",
    "                    verbose=2,\n",
    "                    callbacks = [callbacks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t9RVDcYEmNee"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'r', label = 'Training Accuracy')\n",
    "plt.plot(epochs, val_acc, 'b', label = 'Validation Accuracy')\n",
    "plt.title('Training and Validation accuracy')\n",
    "plt.legend(loc = 'best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MWHiun9gMq6l"
   },
   "outputs": [],
   "source": [
    "from skimage.io import imsave, imread\n",
    "from skimage.transform import resize\n",
    "import numpy as np\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "X_test = []\n",
    "y_test = []\n",
    "labels = ['cat', 'dog']\n",
    "\n",
    "for i, label in enumerate(labels):\n",
    "  folder = os.path.join(test_dir, label)\n",
    "  files = sorted(os.listdir(folder))\n",
    "  files = [x for x in files if x.endswith('.jpg')]\n",
    "  for k, file in enumerate(files):\n",
    "    image_path = os.path.join(folder, file)\n",
    "    image = imread(image_path)/255.\n",
    "    image = resize(image,(320,320))\n",
    "    X_test.append(image)\n",
    "    category = os.path.split(folder)[-1]\n",
    "    y_test.append(i)\n",
    "\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "#Menampilkan bentuk dari masing-masing dataset\n",
    "for image_batch, label_batch in train_generator:\n",
    "  break\n",
    "print(\"Bentuk array dari dataset train (pelatihan) adalah:\", image_batch.shape, label_batch.shape)\n",
    "for image_batch, label_batch in val_generator:\n",
    "  break\n",
    "print(\"Bentuk array dari dataset validation (validasi) adalah:\", image_batch.shape, label_batch.shape)\n",
    "print(\"Bentuk array dari dataset test (pengujian) adalah:\", X_test.shape, y_test.shape)\n",
    "\n",
    "y_test2 = to_categorical(y_test)\n",
    "X_test3 = X_test\n",
    "y_test3 = y_test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wcsf8GYimeg6"
   },
   "outputs": [],
   "source": [
    "#Memeriksa matriks model\n",
    "print(model.metrics_names)\n",
    "#Evaluasi data test\n",
    "print(model.evaluate(X_test3, y_test3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XNlL-yItmgV3"
   },
   "outputs": [],
   "source": [
    "y_true = np.argmax(y_test2, axis=1)\n",
    "\n",
    "#Label prediksi\n",
    "Y_pred = model.predict(X_test)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "\n",
    "print(y_true)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vVsGpF3cmhcS"
   },
   "outputs": [],
   "source": [
    "n = 4 #Jangan melampaui *nilai dari gambar test -1)\n",
    "\n",
    "plt.imshow(X_test[n])\n",
    "plt.show()\n",
    "\n",
    "true_label = np.argmax(y_test2, axis=1)[n]\n",
    "print(\"Label yang benar adalah:\", true_label,\":\", labels[true_label])\n",
    "prediction = model.predict(X_test[n][np.newaxis,...])[0]\n",
    "print(\"Nilai yang diprediksi adalah:\", prediction)\n",
    "predicted_label = np.argmax(prediction)\n",
    "print(\"Label yang diprediksi adalah:\", predicted_label,\":\", labels[predicted_label])\n",
    "\n",
    "if true_label == predicted_label:\n",
    "  print(\"Prediksi benar\")\n",
    "else:\n",
    "  print(\"Prediksi salah\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ozZBiKHbmj0B"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, classes,\n",
    "                          normalize=False,\n",
    "                          title=None,\n",
    "                          cmap=plt.cm.Blues):\n",
    "  if not title:\n",
    "    if normalize:\n",
    "      title = \"Normalized confusion matrix\"\n",
    "    else:\n",
    "      title = \"Confusion matrix, without normalization\"\n",
    "\n",
    "  #Compute confusion matrix\n",
    "  cm = confusion_matrix(y_true, y_pred)\n",
    "  if normalize:\n",
    "    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    print(\"Normalized confusion matrix\")\n",
    "  else:\n",
    "    print(\"Confusion matrix, without normalization\")\n",
    "\n",
    "  print(cm)\n",
    "\n",
    "  fig, ax = plt.subplots(figsize=(5,5))\n",
    "  im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "  ax.set(xticks=np.arange(cm.shape[1]),\n",
    "         yticks=np.arange(cm.shape[0]),\n",
    "         #... and label them with the respective list entries\n",
    "         xticklabels=classes, yticklabels=classes,\n",
    "         title=title,\n",
    "         ylabel='Label Benar',\n",
    "         xlabel='Label Prediksi') \n",
    "  \n",
    "  #rotate the tick labels and set their alignment.\n",
    "  plt.setp(ax.get_xticklabels(), rotation=45, ha='right', rotation_mode='anchor')\n",
    "\n",
    "  #loop over data dimensions and create text annotations.\n",
    "  fmt = '.2f' if normalize else 'd'\n",
    "  thresh = cm.max() / 2.\n",
    "  for i in range(cm.shape[0]):\n",
    "    for j in range(cm.shape[1]):\n",
    "      ax.text(j, i, format(cm[i, j], fmt),\n",
    "              ha='center', va='center',\n",
    "              color='white' if cm[i, j] > thresh else 'black')\n",
    "  fig.tight_layout()\n",
    "  return ax\n",
    "\n",
    "np.set_printoptions(precision=2)\n",
    "plot_confusion_matrix(y_true, y_pred, classes=labels, normalize=True, title=\"Normalize confusion matrix\")\n",
    "print(classification_report(y_true, y_pred, target_names=labels))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
